{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca13028-0b6f-4325-8f76-a9a2bfcbb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\ASUS\\virtual mouse\")  # Add path to sys.path\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0758d0ee-0902-463f-8236-c16801f5519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7,\n",
    "    max_num_hands = 1,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e18dc4-3af1-46b6-b41f-e7738783af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_finger_tip(processed):\n",
    "    if processed.multi_hand_landmarks:  \n",
    "        hand_landmarks = processed.multi_hand_landmarks[0]  # ✅ Use '=' instead of 'in'\n",
    "        return hand_landmarks.landmark[mpHands.HandLandmark.INDEX_FINGER_TIP]  # ✅ Use '[]' instead of '{}'\n",
    "\n",
    "    return None  # ✅ Proper indentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83af5eb3-d790-48f1-b3d0-dcd11ed7f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  move_mouse(index_finger_tip):\n",
    "    if index_finger_tip is not None:\n",
    "            x = int(index_finger_tip.x * screen_width)\n",
    "            x = int(index_finger_tip.x * screen_height)\n",
    "            pyautogui.moveTo(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9648fafd-4d5b-48af-9703-7321a42dc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_gestures(frame, landmark_list, processed):\n",
    "    if len(landmark_list) > 21:  # ✅ Use 'landmark_list' (not 'landmarks_list')\n",
    "\n",
    "        index_finger_tip = find_finger_tip(processed)\n",
    "        print(index_finger_tip)\n",
    "\n",
    "        # ✅ Corrected distance calculation (between thumb and index finger tip)\n",
    "        thumb_index_dist = util.get_distance(landmark_list[4], landmark_list[8])  \n",
    "\n",
    "        # ✅ Corrected angle calculation\n",
    "        if thumb_index_dist < 50 and util.get_angle(landmark_list[5], landmark_list[6], landmark_list[8]) > 90:\n",
    "            move_mouse(index_finger_tip)  # ✅ Ensure index_finger_tip contains (x, y) coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5bcd8b-1880-4881-bfdf-ae14f34b4285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Disable PyAutoGUI fail-safe\n",
    "pyautogui.FAILSAFE = False  \n",
    "\n",
    "# Initialize Mediapipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "\n",
    "# Get screen size\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "click_threshold = 20  # Distance between index and thumb for left click\n",
    "right_click_threshold = 20  # Distance between middle and thumb for right click\n",
    "was_pinch = False  # Track if pinch was previously detected\n",
    "was_right_pinch = False  # Track if right-click pinch was detected\n",
    "last_click_time = 0  # Track last click time to prevent double clicks\n",
    "click_delay = 0.2  # Delay to prevent unintended double clicks\n",
    "\n",
    "active_hand_id = None  # Track the active hand\n",
    "cursor_locked = False  # Prevent cursor movement during pinch\n",
    "SENSITIVITY = 2.0  # Adjusted cursor movement sensitivity for smoother control\n",
    "\n",
    "prev_hand_x, prev_hand_y = None, None  # Track previous hand position\n",
    "\n",
    "# Function to check if ring and pinky fingers are closed\n",
    "def are_ring_pinky_closed(landmarks):\n",
    "    return landmarks[16][1] > landmarks[13][1] and landmarks[20][1] > landmarks[17][1]\n",
    "\n",
    "# Gesture detection function\n",
    "def detect_gestures(frame, landmarks, hand_id):\n",
    "    global was_pinch, was_right_pinch, last_click_time, active_hand_id, cursor_locked\n",
    "    global prev_hand_x, prev_hand_y\n",
    "\n",
    "    # Ignore new hands until the active one disappears\n",
    "    if active_hand_id is None:\n",
    "        active_hand_id = hand_id\n",
    "    elif active_hand_id != hand_id:\n",
    "        return\n",
    "\n",
    "    # Check if ring and pinky fingers are closed\n",
    "    fingers_closed = are_ring_pinky_closed(landmarks)\n",
    "    if not fingers_closed:\n",
    "        prev_hand_x, prev_hand_y = None, None  # Reset hand tracking when fingers are open\n",
    "        return  # Stop movement if fingers are open\n",
    "\n",
    "    # Get fingertip positions\n",
    "    index_tip = landmarks[8]\n",
    "    thumb_tip = landmarks[4]\n",
    "    middle_tip = landmarks[12]\n",
    "\n",
    "    # Click detection (Pinch Gesture for Left Click)\n",
    "    pinch_detected = np.linalg.norm(np.array(index_tip) - np.array(thumb_tip)) < click_threshold\n",
    "    right_pinch_detected = np.linalg.norm(np.array(middle_tip) - np.array(thumb_tip)) < right_click_threshold\n",
    "\n",
    "    current_time = time.time()\n",
    "    if pinch_detected and not was_pinch and (current_time - last_click_time > click_delay):\n",
    "        pyautogui.click()  # Left Click\n",
    "        last_click_time = current_time\n",
    "        cursor_locked = True  # Lock cursor movement during click\n",
    "    elif right_pinch_detected and not was_right_pinch and (current_time - last_click_time > click_delay):\n",
    "        pyautogui.rightClick()  # Right Click\n",
    "        last_click_time = current_time\n",
    "        cursor_locked = True  # Lock cursor movement during click\n",
    "    elif not pinch_detected and not right_pinch_detected:\n",
    "        cursor_locked = False  # Unlock cursor when pinch is released\n",
    "    \n",
    "    was_pinch = pinch_detected  # Update pinch state\n",
    "    was_right_pinch = right_pinch_detected\n",
    "\n",
    "    # Only move cursor if not locked\n",
    "    if not cursor_locked:\n",
    "        if prev_hand_x is None or prev_hand_y is None:\n",
    "            prev_hand_x, prev_hand_y = index_tip[0], index_tip[1]  # Initialize hand tracking\n",
    "        \n",
    "        dx = (index_tip[0] - prev_hand_x) / frame.shape[1] * screen_width\n",
    "        dy = (index_tip[1] - prev_hand_y) / frame.shape[0] * screen_height\n",
    "        \n",
    "        cursor_x = max(1, min(screen_width - 1, int(pyautogui.position()[0] + dx * SENSITIVITY)))\n",
    "        cursor_y = max(1, min(screen_height - 1, int(pyautogui.position()[1] + dy * SENSITIVITY)))\n",
    "        \n",
    "        pyautogui.moveTo(cursor_x, cursor_y, duration=0.02)\n",
    "        prev_hand_x, prev_hand_y = index_tip[0], index_tip[1]\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    global active_hand_id\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)  # Mirror image\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            if active_hand_id is None:\n",
    "                active_hand_id = 0\n",
    "            \n",
    "            hand_landmarks = results.multi_hand_landmarks[active_hand_id]\n",
    "            landmarks_list = [(int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])) for lm in hand_landmarks.landmark]\n",
    "            detect_gestures(frame, landmarks_list, active_hand_id)\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        else:\n",
    "            active_hand_id = None\n",
    "\n",
    "        cv2.imshow(\"Virtual Mouse\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  \n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf95e6-917c-410f-81dd-aeea82f71152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
